%-----------------------------------------------------------------------------------------

\section{Introduction and Motivation}
%-----------------------------------------------------------------------------------------

Data sets hava risen dramatically over the past few years, and these data sets have become increasingly complicated to analyse. How to deal with large amounts of data has become a challenge in certain fields\cite{Larameea}. According to \cite{Ward2015}, when receiving large volumes of information, people tend to use sight as the main sense to understand it. Data visualization, as a mechanism  using graphics to represent data \cite{Ward2015}, provides a good solution in exploring huge sets of complicated data.
As stated by \cite{Williams1995}, data visualization is defined as "the visual representation of a domain space using graphics, images, animated sequences, and sound augmentation to present the data, structure, and dynamic behaviour of large, complex data sets that represent systems, events, processes, objects and concepts"\cite{Williams1995}. By applying techniques of data visualization, more information can be explored.
 
Text data emerges in large numbers every day on newspapers, blogs, and social media, etc. Hence, exacting information from text data is becoming highly needed. For example, in order to understanding information in a short time, we can filter the “stop word”  to get the key information in a text. In certain study area, studying the relationship between words, sentences and texts’ structure may help researchers to understand important information hiding in the text. For example, in archeologists’ lab, analyzing the text they found from historic site may help them understand the dates of files, events happened, or the host of the grave, even without knowing the meaning of the ancient language. Similarly in the archeological industry, techniques in text data analyzing is fundamental and significant in translation study. Many institutes rely on knowledge of text data analysis to explore the variation of language in history, style of authors, as well as the life status people in particular period of time. 

The ways to analyze and present text data has become a popular topic as the volume of the text data is often huge and complicated in format, genre, and morphology. For instance, languages inherit from different roots may lead to different expressions when translating from one to another. Authors of different eras or regions may use different words to express same things. Same contents may appear in different style of expressions according to the purpose of texts. To deal with these problems, text data can be analyzed and represented from lexical, syntactic and semantic perspective {IDVBook}, so that the unstructured text can be converted to structured data. Calculating frequency and weights of words can help to explore the information of content. There have been plentiful tools to visualization the structure of text data, such as Word Clouds, Word Tree, Tex Arc, etc. And for different research purpose, text data are often analyzed separately in single document and a collection of documents.

Whereas some existing tools for textual data visualization, as well as existing works in such area of translation comparisons, challenges exist in this project. On one hand, the existing software indicates mostly the vocabulary of the texts. And in most cases, tools such as Wordle, Word Tree, and TextArc are all adequate for single text document(Paley, 2002). On the other hand, existing tools provide limited comparison information for researchers and linguistics. Another challenge is that the data set we are dealing is in huge amount and complex characteristics which include millions of words in text, various genres and styles.
More concretely, the aims of the project are as follows:

To develop an interactive visualization system that enable the researchers in the College of Art and Humanities to explore detailed translation information of different versions. 

To design a software of textual data visualization to display more information by compare different versions of translations, such as time span, genre, interpretation, etc. 

To explore potential solutions in textual data visualization for difficulties in translation comparison, such as parallel text and data filtering.
The remainder of this report is organized as follows: the second section discusses the related work and existing tools of textual data visualization. The third section specify the content of this project in detail, which include the data description, project feature and related technology. The forth section presents the plan for this project. Section five reviews the existing works and conclude this report.

William Shakespeare, one of the most famous litterateur, has contributed numerous plays and poems to the world. These works have been translated and retranslated many times into various forms in different languages. Studying the evolutions and variations of different versions of these translations has been growing an important topic for cultural and literacy study (Alrehiely, 2014). Othello, as one of the greatest tragedies of Shakespeare, are translated more than 60 times in German by now {Visualizing Translation Variation: Shakespeare’s Othello }. 

It has also attracted the interest of the researchers in the College of Arts and Humanities at Swansea University in studying the version variation of German translations of Othello. They provide a collection of 55 different German translations of Othello (1604). The time span of these translation is from 1766 to 2010. And there are also different genres such as poems, prose, as well as play. Applying data visualization techniques to help to represent these text data will contribute to new research in Shakespeare’s work studying, and visualization exploring.

Using textual data visualization as an assistance to explore the text data of Othello’s translations will benefit for researchers to understand the changes, interactions, and impacts of these translation versions and cultures, time span, styles (Cheesman 2012). Based on the work of {ShakerVis: Visual analysis of segment variation of German translations of Shakespeare’s Othello}, {VISUALIZATION OF VERSION VARIATION}, and {http://www.delightedbeauty.org/vvv/Home/Project}, we attempt to develop an interactive visualization system aims to allow our users to view, compare, and analyze tokens in each version. The visualization tool will be designed to assist in viewing variation of tokens in different translation versions, and in comparing the varieties of tokens after applying different methods to process the text data. Apart from the essential information about each version, such as the author, data of publication, there are three unique information of data are provided: the frequency of tokens, weight of tokens, and results from lemmatization for tokens. 

The outcomes of the visualization system should be helpful to understand of the variation of word morphologies, varieties of text styles, as well as the complex features of German language. It also contributes to comprehend the dynamics of literature, the differences between language, and the perception of translating cultures. Moreover, this project will provide a visualization tool for books, articles, newspapers, etc., to represent large sets of text data.  

However, there exists some challenges in this project. As a highly inflected language, German is featured as complex grammar structure and numerous compoundwords. With the German Shakespeare text data in this project, several special problems are caused by antiquated language, and poetic orthography. The former means some words used in the 18th or 19th century may not be in the lexis of training corpora, if these are based on 20th/21st century sources. And by using the poetic orthography , take “verloren” (meaning: lost) for example, the word normally written as “verloren”, also can be spelled verlor'n, or verlorn in some places in Shakespeare texts (the word normally has 3 syllables, pronounced VER-LOR-RUN, but the writer wants it to be spoken as 2 syllables, VER-LORN). This kind of situation happens a lot. Yet there’s no effective algorithms to recognise these forms. To find a solution for for these problems, some methods from Natural Language Processing may be applied, such as lemmatization.

Choosing this project for my dissertation was account of my interest in the field of data visualization and language analysis. The background of programming and language studying further my comprehension in data analysis and processing. Developing a project such as Translation Visualisation is becoming a significant topic for language studying and text data processing.

Following {Bob’s Project Guidelines}, the rest of this paper is structured as follows: Section 1 to section 4 are modified versions of work previously presented by the author in {Xiaoxiao’s project specification}. Section 2 details the background research, along with the literature review, introduction to existing systems, and data characteristics. Section 3 details the specification of the project which includes the features specification of software and technology choices. Section 4 presents the approach of the project, time arrangement and potential risks. Section 5 provides an overview of project design. Section 6 describes how the project is implemented. In section 7, we provide the performance and feedback from a domain expert as evaluation. And section 8 draws a conclusion of this project and section 9 discusses the potential further work. 



